
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A unified library for estimating effective dimensionality.">
      
      
      
        <link rel="canonical" href="https://amanasci.github.io/EffDim/theory/">
      
      
        <link rel="prev" href="../tutorials/geometric_analysis/">
      
      
        <link rel="next" href="../api/">
      
      
        
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Theory - EffDim</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#theory-estimators" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="EffDim" class="md-header__button md-logo" aria-label="EffDim" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            EffDim
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Theory
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/amanasci/EffDim" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    effdim
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/getting_started/" class="md-tabs__link">
          
  
  
  User Guide

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
  
  Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../deployment/" class="md-tabs__link">
          
  
  
  Development

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="EffDim" class="md-nav__button md-logo" aria-label="EffDim" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    EffDim
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/amanasci/EffDim" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    effdim
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    User Guide
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    User Guide
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/getting_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/comparing_estimators/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Comparing Estimators
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/geometric_analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Geometric Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Theory
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Theory
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mathematical Foundation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#eigenvalue-computation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Eigenvalue Computation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spectral-estimators" class="md-nav__link">
    <span class="md-ellipsis">
      
        Spectral Estimators
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Spectral Estimators">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pca-explained-variance" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCA Explained Variance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#participation-ratio-pr" class="md-nav__link">
    <span class="md-ellipsis">
      
        Participation Ratio (PR)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shannon-effective-dimension" class="md-nav__link">
    <span class="md-ellipsis">
      
        Shannon Effective Dimension
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#renyi-effective-dimension-alpha-entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Rényi Effective Dimension (Alpha-Entropy)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#effective-rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        Effective Rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#geometric-mean-dimension" class="md-nav__link">
    <span class="md-ellipsis">
      
        Geometric Mean Dimension
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stable-rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stable Rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-rank-epsilon-rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        Numerical Rank (Epsilon-Rank)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cumulative-eigenvalue-ratio-cer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cumulative Eigenvalue Ratio (CER)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#geometric-estimators" class="md-nav__link">
    <span class="md-ellipsis">
      
        Geometric Estimators
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Geometric Estimators">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#knn-intrinsic-dimension-mle" class="md-nav__link">
    <span class="md-ellipsis">
      
        kNN Intrinsic Dimension (MLE)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#two-nn" class="md-nav__link">
    <span class="md-ellipsis">
      
        Two-NN
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danco-dimensionality-from-angle-and-norm-concentration" class="md-nav__link">
    <span class="md-ellipsis">
      
        DANCo (Dimensionality from Angle and Norm Concentration)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mind-mli-minimum-distance-single-neighbor" class="md-nav__link">
    <span class="md-ellipsis">
      
        MiND-MLi (Minimum Distance — Single Neighbor)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mind-mlk-minimum-distance-k-neighbors" class="md-nav__link">
    <span class="md-ellipsis">
      
        MiND-MLk (Minimum Distance — k Neighbors)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ess-expected-simplex-skewness" class="md-nav__link">
    <span class="md-ellipsis">
      
        ESS (Expected Simplex Skewness)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tle-tight-localities-estimator" class="md-nav__link">
    <span class="md-ellipsis">
      
        TLE (Tight Localities Estimator)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gmst-geodesic-minimum-spanning-tree" class="md-nav__link">
    <span class="md-ellipsis">
      
        GMST (Geodesic Minimum Spanning Tree)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#assumptions-and-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Assumptions and Limitations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Assumptions and Limitations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#general-assumptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        General Assumptions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#known-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Known Limitations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-which-estimator" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use Which Estimator
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
        References
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Development
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Development
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deployment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Deployment Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mathematical Foundation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#eigenvalue-computation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Eigenvalue Computation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spectral-estimators" class="md-nav__link">
    <span class="md-ellipsis">
      
        Spectral Estimators
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Spectral Estimators">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pca-explained-variance" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCA Explained Variance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#participation-ratio-pr" class="md-nav__link">
    <span class="md-ellipsis">
      
        Participation Ratio (PR)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shannon-effective-dimension" class="md-nav__link">
    <span class="md-ellipsis">
      
        Shannon Effective Dimension
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#renyi-effective-dimension-alpha-entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Rényi Effective Dimension (Alpha-Entropy)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#effective-rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        Effective Rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#geometric-mean-dimension" class="md-nav__link">
    <span class="md-ellipsis">
      
        Geometric Mean Dimension
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stable-rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stable Rank
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numerical-rank-epsilon-rank" class="md-nav__link">
    <span class="md-ellipsis">
      
        Numerical Rank (Epsilon-Rank)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cumulative-eigenvalue-ratio-cer" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cumulative Eigenvalue Ratio (CER)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#geometric-estimators" class="md-nav__link">
    <span class="md-ellipsis">
      
        Geometric Estimators
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Geometric Estimators">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#knn-intrinsic-dimension-mle" class="md-nav__link">
    <span class="md-ellipsis">
      
        kNN Intrinsic Dimension (MLE)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#two-nn" class="md-nav__link">
    <span class="md-ellipsis">
      
        Two-NN
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danco-dimensionality-from-angle-and-norm-concentration" class="md-nav__link">
    <span class="md-ellipsis">
      
        DANCo (Dimensionality from Angle and Norm Concentration)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mind-mli-minimum-distance-single-neighbor" class="md-nav__link">
    <span class="md-ellipsis">
      
        MiND-MLi (Minimum Distance — Single Neighbor)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mind-mlk-minimum-distance-k-neighbors" class="md-nav__link">
    <span class="md-ellipsis">
      
        MiND-MLk (Minimum Distance — k Neighbors)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ess-expected-simplex-skewness" class="md-nav__link">
    <span class="md-ellipsis">
      
        ESS (Expected Simplex Skewness)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tle-tight-localities-estimator" class="md-nav__link">
    <span class="md-ellipsis">
      
        TLE (Tight Localities Estimator)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gmst-geodesic-minimum-spanning-tree" class="md-nav__link">
    <span class="md-ellipsis">
      
        GMST (Geodesic Minimum Spanning Tree)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#assumptions-and-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Assumptions and Limitations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Assumptions and Limitations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#general-assumptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        General Assumptions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#known-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Known Limitations
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-which-estimator" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use Which Estimator
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
        References
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="theory-estimators">Theory &amp; Estimators</h1>
<p>EffDim implements a variety of estimators for "effective dimensionality" (ED). These can be broadly categorized into <strong>Spectral Estimators</strong>, which operate on the eigenvalues (spectrum) of the data's covariance/correlation matrix, and <strong>Geometric Estimators</strong>, which operate on the distances between data points.</p>
<h2 id="mathematical-foundation">Mathematical Foundation</h2>
<h3 id="eigenvalue-computation">Eigenvalue Computation</h3>
<p>For a data matrix <span class="arithmatex">\(\mathbf{X} \in \mathbb{R}^{n \times p}\)</span> with <span class="arithmatex">\(n\)</span> samples and <span class="arithmatex">\(p\)</span> features:</p>
<ol>
<li>
<p><strong>Centering</strong>: The data is centered by subtracting the mean: <span class="arithmatex">\(\tilde{\mathbf{X}} = \mathbf{X} - \frac{1}{n}\mathbf{1}\mathbf{1}^T\mathbf{X}\)</span></p>
</li>
<li>
<p><strong>SVD Decomposition</strong>: <span class="arithmatex">\(\tilde{\mathbf{X}} = \mathbf{U}\mathbf{S}\mathbf{V}^T\)</span> where <span class="arithmatex">\(\mathbf{S}\)</span> contains singular values <span class="arithmatex">\(s_1 \ge s_2 \ge \dots \ge s_{\min(n,p)} \ge 0\)</span></p>
</li>
<li>
<p><strong>Eigenvalue Calculation</strong>: The eigenvalues of the sample covariance matrix are:
   $$ \lambda_i = \frac{s_i^2}{n-1} $$</p>
</li>
</ol>
<p>This follows from <span class="arithmatex">\(\mathbf{C} = \frac{1}{n-1}\tilde{\mathbf{X}}^T\tilde{\mathbf{X}} = \frac{1}{n-1}\mathbf{V}\mathbf{S}^2\mathbf{V}^T\)</span></p>
<ol>
<li><strong>Normalization</strong>: The normalized spectrum (probability distribution) is:
   $$ p_i = \frac{\lambda_i}{\sum_{j=1}^{D} \lambda_j} $$</li>
</ol>
<p>where <span class="arithmatex">\(D = \min(n-1, p)\)</span> is the maximum number of non-zero eigenvalues.</p>
<p><strong>Note</strong>: The implementation uses <span class="arithmatex">\((n-1)\)</span> normalization (sample covariance, unbiased estimator) rather than <span class="arithmatex">\(n\)</span> (population covariance).</p>
<h2 id="spectral-estimators">Spectral Estimators</h2>
<p>These methods rely on the spectrum <span class="arithmatex">\(\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_D \ge 0\)</span> of the covariance matrix. We define the normalized spectrum as <span class="arithmatex">\(p_i = \frac{\lambda_i}{\sum_j \lambda_j}\)</span>, which can be treated as a probability distribution.</p>
<h3 id="pca-explained-variance">PCA Explained Variance</h3>
<p>The classic approach used in Principal Component Analysis. It defines the effective dimension as the number of components required to explain a certain fraction (threshold) of the total variance.</p>
<p><strong>Formula:</strong>
$$ ED_{PCA}(\tau) = \min \left{ k \mid \frac{\sum_{i=1}^k \lambda_i}{\sum_{j=1}^D \lambda_j} \ge \tau \right} $$</p>
<p>where <span class="arithmatex">\(\tau\)</span> is the threshold (default 0.95).</p>
<p><strong>Implementation Details:</strong>
- Uses <code>np.searchsorted</code> for efficient binary search
- Returns integer number of components
- Common thresholds: 0.90, 0.95, 0.99</p>
<p><strong>Interpretation:</strong>
- Direct measure of intrinsic dimensionality
- Easy to interpret: "95% of variance explained by <span class="arithmatex">\(k\)</span> dimensions"
- Depends on threshold choice</p>
<h3 id="participation-ratio-pr">Participation Ratio (PR)</h3>
<p>Widely used in physics and neuroscience to quantify the "spread" of the spectrum. If the variance is equally distributed across <span class="arithmatex">\(N\)</span> dimensions, <span class="arithmatex">\(PR=N\)</span>. If it is concentrated in 1 dimension, <span class="arithmatex">\(PR=1\)</span>.</p>
<p><strong>Formula:</strong>
$$ PR = \frac{\left(\sum_{i=1}^D \lambda_i\right)^2}{\sum_{i=1}^D \lambda_i^2} = \frac{1}{\sum_{i=1}^D p_i^2} $$</p>
<p><strong>Mathematical Equivalence:</strong>
The Participation Ratio is equivalent to the Rényi Effective Dimension with <span class="arithmatex">\(\alpha = 2\)</span>:
$$ PR = \exp\left(\frac{1}{1-2} \ln \sum_i p_i^2\right) = \left(\sum_i p_i^2\right)^{-1} = \frac{1}{\sum_i p_i^2} $$</p>
<p><strong>Implementation Details:</strong>
- Works with eigenvalues <span class="arithmatex">\(\lambda_i\)</span> directly (scale-invariant)
- Protects against division by zero
- Continuous (non-integer) output</p>
<p><strong>Interpretation:</strong>
- <span class="arithmatex">\(PR = D\)</span> when all eigenvalues are equal (maximum spread)
- <span class="arithmatex">\(PR = 1\)</span> when one eigenvalue dominates (minimum spread)
- Robust to small eigenvalues (inverse quadratic weighting)</p>
<h3 id="shannon-effective-dimension">Shannon Effective Dimension</h3>
<p>Based on the Shannon entropy of the spectral distribution. It corresponds to the exponential of the entropy.</p>
<p><strong>Formula:</strong>
$$ H = - \sum_{i=1}^D p_i \ln p_i $$
$$ ED_{Shannon} = \exp(H) $$</p>
<p><strong>Implementation Details:</strong>
- Filters zero probabilities before computing <span class="arithmatex">\(\ln p_i\)</span> to avoid <span class="arithmatex">\(\ln(0)\)</span>
- Returns exponential of entropy (not entropy itself)
- Also known as "Effective Rank" or "Perplexity"</p>
<p><strong>Interpretation:</strong>
- <span class="arithmatex">\(ED_{Shannon} = D\)</span> when all eigenvalues are equal
- <span class="arithmatex">\(ED_{Shannon} = 1\)</span> when one eigenvalue dominates
- Represents the "number of equally likely states"
- More sensitive to tail of distribution than PR
- Related to information content of the spectrum</p>
<p><strong>Connection to Information Theory:</strong>
The Shannon ED can be interpreted as the effective number of "independent" dimensions, where each dimension contributes equally to the total variance in an information-theoretic sense.</p>
<h3 id="renyi-effective-dimension-alpha-entropy">Rényi Effective Dimension (Alpha-Entropy)</h3>
<p>A generalization of the Shannon dimension using Rényi entropy of order <span class="arithmatex">\(\alpha\)</span>.</p>
<p><strong>Formula:</strong>
$$ H_\alpha = \frac{1}{1-\alpha} \ln \left(\sum_{i=1}^D p_i^\alpha\right) $$
$$ ED_{\alpha} = \exp(H_\alpha) = \left(\sum_{i=1}^D p_i^\alpha\right)^{\frac{1}{1-\alpha}} $$</p>
<p><strong>Special Cases:</strong>
*   <span class="arithmatex">\(\alpha \to 1\)</span>: Converges to Shannon Effective Dimension (via L'Hôpital's rule)
*   <span class="arithmatex">\(\alpha = 2\)</span>: <span class="arithmatex">\(ED_2 = \left(\sum_i p_i^2\right)^{-1} = PR\)</span> (Participation Ratio)
*   <span class="arithmatex">\(\alpha = 0\)</span>: Counts non-zero eigenvalues (algebraic rank)
*   <span class="arithmatex">\(\alpha \to \infty\)</span>: <span class="arithmatex">\(ED_\infty = 1/\max_i p_i\)</span> (inverse of largest probability)</p>
<p><strong>Implementation Details:</strong>
- Validates <span class="arithmatex">\(\alpha &gt; 0\)</span> and <span class="arithmatex">\(\alpha \neq 1\)</span>
- For <span class="arithmatex">\(\alpha = 1\)</span>, use Shannon ED instead
- Protects against zero denominator</p>
<p><strong>Interpretation:</strong>
- <span class="arithmatex">\(\alpha\)</span> controls sensitivity to rare vs common components
- Small <span class="arithmatex">\(\alpha\)</span> (e.g., 0.5): More weight to rare eigenvalues
- Large <span class="arithmatex">\(\alpha\)</span> (e.g., 5): More weight to dominant eigenvalues
- Provides a one-parameter family interpolating between different notions of dimension</p>
<p><strong>When to Use Which Alpha:</strong>
- <span class="arithmatex">\(\alpha = 2\)</span> (PR): Balanced measure, equivalent to inverse Simpson index
- <span class="arithmatex">\(\alpha = 3, 4, 5\)</span>: Emphasize dominant components
- For general analysis, <span class="arithmatex">\(\alpha = 2\)</span> (PR) is most common</p>
<h3 id="effective-rank">Effective Rank</h3>
<p>Often used in matrix completion and low-rank approximation contexts. EffDim implements this as an alias for Shannon Effective Dimension.</p>
<h3 id="geometric-mean-dimension">Geometric Mean Dimension</h3>
<p>A dimension proxy based on the ratio of the arithmetic mean to the geometric mean of the spectrum.</p>
<p><strong>Formula:</strong>
$$ d_{GM} = \frac{\text{AM}(\lambda)}{\text{GM}(\lambda)} = \frac{\frac{1}{D'} \sum_{i=1}^{D'} \lambda_i}{\left(\prod_{i=1}^{D'} \lambda_i\right)^{1/D'}} $$</p>
<p>where <span class="arithmatex">\(D'\)</span> is the number of positive eigenvalues, <span class="arithmatex">\(\lambda_i &gt; 0\)</span>.</p>
<p><strong>Equivalent Form:</strong>
$$ d_{GM} = \frac{\frac{1}{D'} \sum_{i=1}^{D'} \lambda_i}{\exp\left(\frac{1}{D'} \sum_{i=1}^{D'} \ln \lambda_i\right)} $$</p>
<p><strong>Implementation Details:</strong>
- Filters zero/negative eigenvalues before computation
- Uses <span class="arithmatex">\(\ln\)</span> for numerical stability in geometric mean
- Scale-invariant (gives same result for eigenvalues or probabilities)
- Returns 0.0 if no positive eigenvalues</p>
<p><strong>Interpretation:</strong>
- <span class="arithmatex">\(d_{GM} = 1\)</span> when all positive eigenvalues are equal
- <span class="arithmatex">\(d_{GM} &gt; 1\)</span> indicates spread in the spectrum
- By AM-GM inequality: <span class="arithmatex">\(d_{GM} \ge 1\)</span> always
- Larger values indicate more inequality in eigenvalue distribution
- Related to condition number of the covariance matrix</p>
<p><strong>Note on Scale Invariance:</strong>
Because <span class="arithmatex">\(\text{AM}(c\lambda) = c \cdot \text{AM}(\lambda)\)</span> and <span class="arithmatex">\(\text{GM}(c\lambda) = c \cdot \text{GM}(\lambda)\)</span>, the ratio is unchanged by scaling. Therefore, using eigenvalues <span class="arithmatex">\(\lambda_i\)</span> or normalized probabilities <span class="arithmatex">\(p_i\)</span> yields the same result.</p>
<h3 id="stable-rank">Stable Rank</h3>
<p>A stable alternative to the algebraic rank, often used in high-dimensional probability. It is robust to small perturbations of the singular values.</p>
<div class="arithmatex">\[ R_{stable} = \frac{\sum_i \lambda_i}{\max_i \lambda_i} \]</div>
<p>where <span class="arithmatex">\(\lambda_i\)</span> are the eigenvalues (variances).</p>
<h3 id="numerical-rank-epsilon-rank">Numerical Rank (Epsilon-Rank)</h3>
<p>The number of singular values greater than a specific threshold <span class="arithmatex">\(\epsilon\)</span>.</p>
<div class="arithmatex">\[ rank_\epsilon(A) = | \{ \sigma_i \mid \sigma_i &gt; \epsilon \} | \]</div>
<p>If <span class="arithmatex">\(\epsilon\)</span> is not provided, it defaults to a value based on the machine precision and the largest singular value.</p>
<h3 id="cumulative-eigenvalue-ratio-cer">Cumulative Eigenvalue Ratio (CER)</h3>
<p>A weighted sum of the normalized spectrum, giving more weight to earlier components.</p>
<div class="arithmatex">\[ CER = \sum_{i=1}^D w_i p_i \]</div>
<p>where weights decrease linearly from 1 to 0.</p>
<h2 id="geometric-estimators">Geometric Estimators</h2>
<p>These methods estimate the intrinsic dimension (ID) of the data manifold based on local neighborhoods, without relying on global projections like PCA.</p>
<h3 id="knn-intrinsic-dimension-mle">kNN Intrinsic Dimension (MLE)</h3>
<p>The Maximum Likelihood Estimator proposed by Levina and Bickel (2005). It estimates dimension by examining the ratio of distances to the <span class="arithmatex">\(k\)</span>-th nearest neighbor.</p>
<p><strong>Reference:</strong> Levina, E., &amp; Bickel, P. J. (2005). Maximum likelihood estimation of intrinsic dimension. <em>Advances in Neural Information Processing Systems</em> 17 (NIPS 2004).</p>
<p><strong>Formula:</strong>
For each point <span class="arithmatex">\(x_i\)</span>, let <span class="arithmatex">\(r_1(x_i) \le r_2(x_i) \le \dots \le r_k(x_i)\)</span> be the distances to its <span class="arithmatex">\(k\)</span> nearest neighbors. The local dimension estimate is:</p>
<div class="arithmatex">\[ \hat{d}_k(x_i) = \left[ \frac{1}{k-1} \sum_{j=1}^{k-1} \ln \frac{r_k(x_i)}{r_j(x_i)} \right]^{-1} = \frac{k-1}{\sum_{j=1}^{k-1} \ln r_k(x_i) - \ln r_j(x_i)} \]</div>
<p>The global estimate is the average over all points:
$$ \hat{d}<em i="1">k = \frac{1}{n} \sum</em>_k(x_i) $$}^n \hat{d</p>
<p><strong>Implementation Details:</strong>
- Uses FAISS library for efficient kNN search with L2 distance
- Adds <span class="arithmatex">\(\epsilon = 10^{-10}\)</span> to distances to prevent <span class="arithmatex">\(\ln(0)\)</span>
- Uses <code>np.errstate</code> to handle potential numerical issues
- Default <span class="arithmatex">\(k = 10\)</span> neighbors
- Complexity: <span class="arithmatex">\(O(n^2)\)</span> naive, <span class="arithmatex">\(O(n \log n)\)</span> with FAISS indexing</p>
<p><strong>Numerical Stability:</strong>
- <span class="arithmatex">\(\ln(r_k/r_j) = \ln r_k - \ln r_j\)</span> computed in log-space for stability
- Epsilon added to denominator to prevent division by zero
- Handles duplicate points (distance = 0) gracefully</p>
<p><strong>When to Use:</strong>
- Data lies on or near a low-dimensional manifold
- Sufficient sample density (at least <span class="arithmatex">\(k\)</span> neighbors per point)
- Metric (Euclidean) distance is meaningful</p>
<p><strong>Choosing k:</strong>
- Too small <span class="arithmatex">\(k\)</span>: High variance, sensitive to noise
- Too large <span class="arithmatex">\(k\)</span>: Bias if curvature is significant
- Typical range: <span class="arithmatex">\(k \in [5, 20]\)</span>
- Rule of thumb: <span class="arithmatex">\(k \approx \sqrt{n}\)</span> for small datasets</p>
<h3 id="two-nn">Two-NN</h3>
<p>A robust estimator proposed by Facco et al. (2017) that relies only on the distances to the first two nearest neighbors. It is less sensitive to density variations and curvature than standard kNN.</p>
<p><strong>Reference:</strong> Facco, E., d'Errico, M., Rodriguez, A., &amp; Laio, A. (2017). Estimating the intrinsic dimension of datasets by a minimal neighborhood information. <em>Scientific Reports</em>, 7(1), 12140. DOI: 10.1038/s41598-017-11873-y</p>
<p><strong>Theory:</strong>
Assumes data is uniformly distributed on a <span class="arithmatex">\(d\)</span>-dimensional manifold. The ratio <span class="arithmatex">\(\mu_i = r_2(x_i) / r_1(x_i)\)</span> follows a distribution with CDF:
$$ F(\mu) = 1 - \mu^{-d} $$</p>
<p>Taking logarithms:
$$ -\ln(1 - F(\mu)) = d \cdot \ln(\mu) $$</p>
<p><strong>Formula:</strong>
1. For each point <span class="arithmatex">\(x_i\)</span>, compute <span class="arithmatex">\(\mu_i = r_2(x_i) / r_1(x_i)\)</span>
2. Sort the <span class="arithmatex">\(\mu_i\)</span> values: <span class="arithmatex">\(\mu_{(1)} \le \mu_{(2)} \le \dots \le \mu_{(n)}\)</span>
3. Use empirical CDF: <span class="arithmatex">\(F(\mu_{(i)}) = i/n\)</span> for <span class="arithmatex">\(i = 1, \dots, n-1\)</span> (drop last to avoid <span class="arithmatex">\(\ln(0)\)</span>)
4. Fit linear regression through origin:
   $$ y_i = d \cdot x_i $$
   where <span class="arithmatex">\(x_i = \ln(\mu_{(i)})\)</span> and <span class="arithmatex">\(y_i = -\ln(1 - i/n)\)</span>
5. Estimate: <span class="arithmatex">\(\hat{d} = \frac{\sum_i x_i y_i}{\sum_i x_i^2}\)</span></p>
<p><strong>Implementation Details:</strong>
- Uses FAISS for kNN search (k=2)
- Adds <span class="arithmatex">\(\epsilon = 10^{-10}\)</span> to distances
- Drops last point to avoid <span class="arithmatex">\(F=1\)</span> causing <span class="arithmatex">\(\ln(0)\)</span>
- Linear regression uses dot product formula (no intercept)
- Complexity: <span class="arithmatex">\(O(n \log n)\)</span> with FAISS</p>
<p><strong>Numerical Stability:</strong>
- Epsilon prevents division by zero in <span class="arithmatex">\(\mu = r_2/r_1\)</span>
- Dropping last point prevents <span class="arithmatex">\(\ln(1-1) = \ln(0)\)</span>
- Checks for zero variance in <span class="arithmatex">\(\mu\)</span> values</p>
<p><strong>Advantages over MLE:</strong>
- More robust to density variations
- Less sensitive to manifold curvature
- Requires only 2 neighbors (works with smaller samples)
- No parameter tuning required</p>
<p><strong>When to Use:</strong>
- Preferred for datasets with non-uniform density
- When sample size is limited
- When you want parameter-free estimation</p>
<h3 id="danco-dimensionality-from-angle-and-norm-concentration">DANCo (Dimensionality from Angle and Norm Concentration)</h3>
<p>Exploits the concentration of angles between nearest neighbor vectors to estimate intrinsic dimension.</p>
<p><strong>Reference:</strong> Ceruti, C., et al. (2012). DANCo: Dimensionality from Angle and Norm Concentration. <em>arXiv:1206.3881</em>.</p>
<p><strong>Theory:</strong>
In a <span class="arithmatex">\(d\)</span>-dimensional space, the angles between random vectors concentrate around <span class="arithmatex">\(\pi/2\)</span> as <span class="arithmatex">\(d\)</span> increases. Specifically, for two random unit vectors in <span class="arithmatex">\(\mathbb{R}^d\)</span>, the expected value of <span class="arithmatex">\(\cos^2(\theta) \approx 1/d\)</span>.</p>
<p><strong>Formula:</strong>
1. For each point <span class="arithmatex">\(x_i\)</span>, compute vectors <span class="arithmatex">\(v_{ij} = x_j - x_i\)</span> to its <span class="arithmatex">\(k\)</span> nearest neighbors.
2. Normalize to unit vectors: <span class="arithmatex">\(\hat{v}_{ij} = v_{ij} / \|v_{ij}\|\)</span>.
3. Compute pairwise cosines: <span class="arithmatex">\(\cos(\theta_{jl}) = \hat{v}_{ij} \cdot \hat{v}_{il}\)</span>.
4. Estimate: <span class="arithmatex">\(\hat{d} = 1 / \overline{\cos^2(\theta)}\)</span> where the average is over all points and all pairs.</p>
<p><strong>Implementation Details:</strong>
- Uses FAISS for efficient kNN search
- Adds <span class="arithmatex">\(\epsilon = 10^{-10}\)</span> to norms to prevent division by zero
- Default <span class="arithmatex">\(k = 10\)</span> neighbors
- Uses <code>np.einsum</code> for efficient pairwise cosine computation</p>
<p><strong>When to Use:</strong>
- When angle-based estimation is preferred over distance-based
- For data with complex geometric structure</p>
<h3 id="mind-mli-minimum-distance-single-neighbor">MiND-MLi (Minimum Distance — Single Neighbor)</h3>
<p>Maximum Likelihood Estimator based on the distribution of nearest neighbor distances only.</p>
<p><strong>Reference:</strong> Rozza, A., et al. (2012). Novel high intrinsic dimensionality estimators. <em>Machine Learning</em>, 89(1-2), 37-65.</p>
<p><strong>Formula:</strong>
1. For each point <span class="arithmatex">\(x_i\)</span>, compute the nearest neighbor distance <span class="arithmatex">\(r_1(x_i)\)</span>.
2. Let <span class="arithmatex">\(r_{\max} = \max_i r_1(x_i)\)</span>.
3. Estimate: <span class="arithmatex">\(\hat{d} = n / \sum_{i=1}^n \ln(r_{\max} / r_1(x_i))\)</span>.</p>
<p><strong>Implementation Details:</strong>
- Uses only the single nearest neighbor distance
- Returns 0.0 if all distances are equal (degenerate case)
- Requires at least 3 points</p>
<p><strong>When to Use:</strong>
- When minimal neighborhood information is available
- For quick estimates with low computational cost</p>
<h3 id="mind-mlk-minimum-distance-k-neighbors">MiND-MLk (Minimum Distance — k Neighbors)</h3>
<p>Extension of the Levina-Bickel MLE using the median of per-point estimates for robustness against outliers.</p>
<p><strong>Reference:</strong> Rozza, A., et al. (2012). Novel high intrinsic dimensionality estimators. <em>Machine Learning</em>, 89(1-2), 37-65.</p>
<p><strong>Formula:</strong>
Same per-point estimates as kNN MLE:
$$ \hat{d}<em j="1">k(x_i) = \frac{k-1}{\sum</em> $$}^{k-1} \ln r_k(x_i) - \ln r_j(x_i)</p>
<p>Global estimate uses the <strong>median</strong> instead of the mean:
$$ \hat{d}_k = \text{median}\left(\hat{d}_k(x_1), \dots, \hat{d}_k(x_n)\right) $$</p>
<p><strong>Advantages over standard MLE:</strong>
- More robust to outliers and density inhomogeneities
- The median is less sensitive to extreme per-point estimates</p>
<h3 id="ess-expected-simplex-skewness">ESS (Expected Simplex Skewness)</h3>
<p>Estimates dimension by analyzing the skewness of local simplices formed by nearest neighbors.</p>
<p><strong>Reference:</strong> Johnsson, K., et al. (2015). Low bias local intrinsic dimension estimation from expected simplex skewness. <em>IEEE Trans. PAMI</em>, 37(1), 196-202.</p>
<p><strong>Theory:</strong>
For each point, the <span class="arithmatex">\(k\)</span> nearest neighbors form a simplex. The "skewness" is measured as the squared norm of the mean of unit direction vectors. In <span class="arithmatex">\(d\)</span> dimensions, the expected squared norm of the mean of <span class="arithmatex">\(k\)</span> random unit vectors is approximately <span class="arithmatex">\(1/(k \cdot d)\)</span>.</p>
<p><strong>Formula:</strong>
1. For each point <span class="arithmatex">\(x_i\)</span>, compute unit vectors <span class="arithmatex">\(\hat{v}_{ij}\)</span> to its <span class="arithmatex">\(k\)</span> neighbors.
2. Compute centroid: <span class="arithmatex">\(\bar{v}_i = \frac{1}{k}\sum_{j=1}^k \hat{v}_{ij}\)</span>.
3. Compute skewness: <span class="arithmatex">\(S_i = \|\bar{v}_i\|^2\)</span>.
4. Average: <span class="arithmatex">\(\bar{S} = \frac{1}{n}\sum_{i=1}^n S_i\)</span>.
5. Estimate: <span class="arithmatex">\(\hat{d} = 1 / (k \cdot \bar{S})\)</span>.</p>
<p><strong>When to Use:</strong>
- When low-bias estimation is important
- For manifolds with moderate curvature</p>
<h3 id="tle-tight-localities-estimator">TLE (Tight Localities Estimator)</h3>
<p>Maximizes likelihood on scale-normalized distances, making it more robust to density variations.</p>
<p><strong>Reference:</strong> Amsaleg, L., et al. (2019). Intrinsic dimensionality estimation within tight localities. <em>SDM 2019</em>.</p>
<p><strong>Theory:</strong>
For each point, the distances to <span class="arithmatex">\(k\)</span> neighbors are normalized by the <span class="arithmatex">\(k\)</span>-th neighbor distance: <span class="arithmatex">\(u_j = r_j / r_k\)</span>. Under a <span class="arithmatex">\(d\)</span>-dimensional uniform distribution, each <span class="arithmatex">\(u_j\)</span> follows a <span class="arithmatex">\(\text{Beta}(d, 1)\)</span> distribution with PDF <span class="arithmatex">\(p(u) = d \cdot u^{d-1}\)</span>.</p>
<p><strong>Formula:</strong>
$$ \hat{d}<em j="1">i = \frac{-(k-1)}{\sum</em> $$}^{k-1} \ln u_j} = \frac{k-1}{\sum_{j=1}^{k-1} \ln(r_k / r_j)</p>
<p>The global estimate is <span class="arithmatex">\(\hat{d} = \frac{1}{n}\sum_{i=1}^n \hat{d}_i\)</span>.</p>
<p><strong>Implementation Details:</strong>
- Mathematically equivalent to the Levina-Bickel MLE
- The per-point normalization by <span class="arithmatex">\(r_k\)</span> provides scale invariance</p>
<h3 id="gmst-geodesic-minimum-spanning-tree">GMST (Geodesic Minimum Spanning Tree)</h3>
<p>Estimates dimension from how the total length of the Minimum Spanning Tree (MST) scales with the number of points.</p>
<p><strong>Reference:</strong> Costa, J. A., &amp; Hero, A. O. (2004). Geodesic entropic graphs for dimension and entropy estimation in manifold learning. <em>IEEE Trans. Signal Processing</em>, 52(8), 2210-2221.</p>
<p><strong>Theory:</strong>
For <span class="arithmatex">\(n\)</span> points sampled uniformly from a <span class="arithmatex">\(d\)</span>-dimensional manifold (<span class="arithmatex">\(d &gt; 1\)</span>), the total MST edge weight scales as:
$$ L_{\text{MST}} \propto n^{(d-1)/d} $$</p>
<p>Taking logarithms: <span class="arithmatex">\(\ln L_{\text{MST}} = \alpha \cdot \ln n + c\)</span>, where <span class="arithmatex">\(\alpha = (d-1)/d\)</span>, giving <span class="arithmatex">\(d = 1/(1-\alpha)\)</span>.</p>
<p><strong>Formula:</strong>
1. Take subsamples of sizes <span class="arithmatex">\(n_1, n_2, \dots\)</span> from the data.
2. For each subsample, compute the MST and its total edge weight <span class="arithmatex">\(L_i\)</span>.
3. Fit linear regression: <span class="arithmatex">\(\ln L_i = \alpha \cdot \ln n_i + c\)</span>.
4. Estimate: <span class="arithmatex">\(\hat{d} = 1 / (1 - \alpha)\)</span>.</p>
<p><strong>Geodesic Mode:</strong>
When <code>geodesic=True</code>, distances are computed along the data manifold using shortest paths on a <span class="arithmatex">\(k\)</span>-NN graph, rather than straight-line Euclidean distances.</p>
<p><strong>Implementation Details:</strong>
- Uses <code>scipy.sparse.csgraph.minimum_spanning_tree</code> for MST computation
- Uses <code>scipy.spatial.distance.pdist</code> for Euclidean distances
- Uses <code>sklearn.neighbors.kneighbors_graph</code> + <code>scipy.sparse.csgraph.shortest_path</code> for geodesic distances
- Subsamples at sizes <span class="arithmatex">\([n/8, n/4, n/2, n]\)</span> with a fixed random seed for reproducibility
- Requires at least 10 points</p>
<p><strong>When to Use:</strong>
- When data lies on a curved manifold (use geodesic mode)
- When graph-based analysis is preferred
- For datasets where local methods may be biased</p>
<hr />
<h2 id="assumptions-and-limitations">Assumptions and Limitations</h2>
<h3 id="general-assumptions">General Assumptions</h3>
<p><strong>Data Requirements:</strong>
- Data should be centered (automatically handled in implementation)
- Sufficient sample size: <span class="arithmatex">\(n \gg d\)</span> for reliable spectral estimates
- Sufficient sample size: <span class="arithmatex">\(n \ge 2k\)</span> for geometric estimates
- No missing values (NaN/Inf not handled)</p>
<p><strong>Spectral Estimators:</strong>
- Assume linear (global) structure
- Best for: Gaussian or approximately Gaussian data
- May overestimate dimension for highly curved manifolds
- Sensitive to outliers (affect eigenvalue spectrum)
- Assume data lies in Euclidean space (not on a non-linear manifold)</p>
<p><strong>Geometric Estimators:</strong>
- Assume local manifold structure
- Best for: Data on or near low-dimensional manifolds
- Require sufficient local sample density
- Assume metric (Euclidean) distance is meaningful
- May fail for highly sparse or non-uniformly sampled data</p>
<h3 id="known-limitations">Known Limitations</h3>
<p><strong>Computational Complexity:</strong>
- SVD: <span class="arithmatex">\(O(\min(n^2p, np^2))\)</span> for full SVD, <span class="arithmatex">\(O(npk)\)</span> for randomized SVD
- MLE: <span class="arithmatex">\(O(n^2)\)</span> for exact kNN, <span class="arithmatex">\(O(n \log n)\)</span> with FAISS indexing
- Two-NN: <span class="arithmatex">\(O(n \log n)\)</span> with FAISS</p>
<p><strong>Sample Size Dependencies:</strong>
- Spectral methods: Eigenvalues stabilize when <span class="arithmatex">\(n \ge 5d\)</span> (rule of thumb)
- MLE: Requires at least <span class="arithmatex">\(k+1\)</span> points, converges when <span class="arithmatex">\(n \ge 100\)</span>
- Two-NN: Requires at least 3 points, more robust for small <span class="arithmatex">\(n\)</span> than MLE
- Small <span class="arithmatex">\(n\)</span>: High variance in all estimates</p>
<p><strong>High-Dimensional Data (<span class="arithmatex">\(p \gg n\)</span>):</strong>
- Only <span class="arithmatex">\(\min(n-1, p)\)</span> eigenvalues are non-zero
- Covariance matrix is rank-deficient
- Spectral methods still work but are limited by <span class="arithmatex">\(n\)</span>
- Consider using randomized SVD for efficiency</p>
<p><strong>Numerical Stability:</strong>
- Very small eigenvalues (<span class="arithmatex">\(\lambda &lt; 10^{-10}\)</span>) may be unstable
- Very large condition numbers may cause issues
- Log of very small values protected by epsilon addition
- Division by zero protected throughout</p>
<h3 id="when-to-use-which-estimator">When to Use Which Estimator</h3>
<p><strong>Use PCA Explained Variance when:</strong>
- You need an interpretable, threshold-based dimension
- Data is approximately Gaussian
- You want to choose how much information to retain</p>
<p><strong>Use Participation Ratio when:</strong>
- You want a continuous measure
- You need mathematical equivalence to Rényi-2
- Comparing across different datasets</p>
<p><strong>Use Shannon ED when:</strong>
- You want an information-theoretic measure
- You need sensitivity to the full spectrum (including tail)
- Comparing to entropy-based methods</p>
<p><strong>Use MLE when:</strong>
- Data lies on a non-linear manifold
- You have sufficient sample density
- You can tune the <span class="arithmatex">\(k\)</span> parameter</p>
<p><strong>Use Two-NN when:</strong>
- You want a robust, parameter-free geometric method
- Sample size is limited
- Data has non-uniform density</p>
<h3 id="references">References</h3>
<p><strong>Spectral Methods:</strong>
- Roy, O., &amp; Vetterli, M. (2007). The effective rank: A measure of effective dimensionality. <em>EUSIPCO</em>.</p>
<p><strong>Geometric Methods:</strong>
- Levina, E., &amp; Bickel, P. J. (2005). Maximum likelihood estimation of intrinsic dimension. <em>NIPS 2004</em>.
- Facco, E., d'Errico, M., Rodriguez, A., &amp; Laio, A. (2017). Estimating the intrinsic dimension of datasets by a minimal neighborhood information. <em>Scientific Reports</em>, 7(1), 12140. DOI: 10.1038/s41598-017-11873-y
- Ceruti, C., et al. (2012). DANCo: Dimensionality from Angle and Norm Concentration. <em>arXiv:1206.3881</em>.
- Rozza, A., et al. (2012). Novel high intrinsic dimensionality estimators. <em>Machine Learning</em>, 89(1-2), 37-65.
- Johnsson, K., et al. (2015). Low bias local intrinsic dimension estimation from expected simplex skewness. <em>IEEE Trans. PAMI</em>, 37(1), 196-202.
- Amsaleg, L., et al. (2019). Intrinsic dimensionality estimation within tight localities. <em>SDM 2019</em>.
- Costa, J. A., &amp; Hero, A. O. (2004). Geodesic entropic graphs for dimension and entropy estimation in manifold learning. <em>IEEE Trans. Signal Processing</em>, 52(8), 2210-2221.</p>
<p><strong>Survey:</strong>
- Camastra, F., &amp; Staiano, A. (2016). Intrinsic dimension estimation: Advances and open problems. <em>Information Sciences</em>, 328, 26-41.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "toc.follow", "content.code.copy", "content.code.annotate"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>